Using Machine Learning to Detect Mistakes in Weight-Lifting Exercises
===
Ivan Corneillet

```{r, echo = FALSE, message = FALSE}
# `gbm` issues a warning advising loading `plyr` before `dplyr`
library(plyr)

library(dplyr)

library(lattice)

# Downsize the fonts for the exploratory plot matrices
trellis.par.set(fontsize = list(text = 6),
	axis.text = list(alpha = 1, cex = 0, font = 0),
	axis.components = list(left = list(tck = 0, pad1 = 0, pad2 = 0),
		top = list(tck = 0, pad1 = 0, pad2 = 0),
		right = list(tck = 0, pad1 = 0, pad2 = 0),
		bottom = list(tck = 0, pad1 = 0, pad2 = 0)))

library(gridExtra)

library(caret)

library(xtable)
```

## Executive Summary

This project aims to reproduce the machine learning section of Velloso et al.'s [paper](http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf) on qualitative activity recognition of weight-lifting exercises.  In their paper, the authors assessed whether techniques on activity recognition (i.e., predict "which" activity as performed) could be extended to quality of execution (i.e., predict "how well" said activity was performed).

We built a number of prediction models and selected a high-performing random forest (`rf`) machine learning algorithm.  Boosting (`gbm`) was a close second followed by naive bayes classifier (`nb`) and linear discriminant analysis (`lda`).  Trees (`rpart`) finished last.  Finally, we used our random forest model to successfully predict 20 different test cases.

## Model

### `classe` variable (outcome)

In this experiment, six participants were asked to perform sets of ten repetitions of the unilateral dumbbell biceps curl both correctly (i.e., exactly according to the specification) (Class A) as well as incorrectly, following a pattern of four common mistakes: Throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D), and throwing the hips to the front (Class E).

### Features (predictors)

In this section, we will examine which features we will include in our model.

#### IMUs' raw data: `{gyros, accel, magnet}_{belt, arm, dumbbell, forearm}_{x, y, z}`

For data recording, the authors used four [inertial measurement units (IMU)](http://en.wikipedia.org/wiki/Inertial_measurement_unit) that they mounted in the users' lumbar belt (`_belt_`), glove (`_arm_`), dumbbell (`_dumbbell_`), and armband (`_forearm_`).  Each IMO provided three-axes (`_x`, `_y`, and `_z`) gyroscope (`gyros_`), acceleration (`accel_`), and magnetometer (`magnet_`) data, totaling `r 3 * 4 * 3` features: `{gyros, accel, magnet}_{belt, arm, dumbbell, forearm}_{x, y, z}`.  This raw data is complete (i.e., there are no missing values) for each observation (row) in the training data and we will be including them in our model.

#### IMUs' calculated data: `{roll, pitch, yaw}_{belt, arm, dumbbell, forearm}` and `total_accel_{belt, arm, dumbbell, forearm}`

For each IMU, the authors also calculated the [Euler angles](http://en.wikipedia.org/wiki/Euler_angles)' roll (`roll_`), pitch (`pitch_`), and yaw (`yaw_`): `{roll, pitch, yaw}_{belt, arm, dumbbell, forearm}` as well as its total acceleration (``total_accel_`): `total_accel_{belt, arm, dumbbell, forearm}`.

These variables were calculated for each observation in the training data and there are no missing values so we will be including these variables in our model as well.

#### Statistical data; by time window, not by observation

Finally, the authors calculated statistical measures over time windows (mean, variance, standard deviation, max, min, amplitude, kurtosis, and skewness) for the Euler angles of each of the four sensors.  However, because we need to predict the class for each of the testing database's 20 measurements **independently** of any other data, we will not incorporate the statistical features in our machine learning model.  This is one difference with what the authors examined in their paper.

The table below summarizes the list of features we selected/didn't select from the dataset and why:

| Dataset variables | Included in our model? | Notes |
|---|---|---|
| `{gyros, accel, magnet}_{belt, arm, dumbbell, forearm}_{x, y, z}` | **Yes** | IMUs' raw data; available for each observation in the dataset |
| `{roll, pitch, yaw}_{belt, arm, dumbbell, forearm}` and `total_accel_{belt, arm, dumbbell, forearm}` | **Yes** | IMUs' calculated data; available for each observation in the dataset |
| Other variables (mean, variance, standard deviation, max, min, amplitude, kurtosis, and skewness) | **No** | Statistical measures over time windows; not available observations we need to predict the outcome in the testing set |

```{r features-training, echo = FALSE}
features.colClasses = c(
	# Belt
	########

	# Roll, pitch, yaw, and acceleration data:
	#   '{roll, pitch, yaw, total_accel}_belt' variables

	rep(x = 'numeric', times = 4),

	rep(x = 'NULL', times = 25), # Skip statistical summary variables

	# Three-axes gyroscope, acceleration, and magnetometer data:
	#   '{gyro, accel, magnet}_belt_{x, y, z}' variables

	rep(x = 'numeric', times = 9),

	# Arm
	#######

	# Roll, pitch, yaw, and acceleration data:
	#   '{roll, pitch, yaw, total_accel}_arm' variables

	rep(x = 'numeric', times = 4),

	rep(x = 'NULL', times = 10), # Skip statistical summary variables

	# Three-axes gyroscope, acceleration, and magnetometer data:
	#   '{gyro, accel, magnet}_arm_{x, y, z}' variables

	rep(x = 'numeric', times = 9),

	rep(x = 'NULL', times = 15), # Skip statistical summary variables

	# Dumbbell
	############

	# Roll, pitch, yaw data:
	#   '{roll, pitch, yaw}_dumbbell' variables

	rep(x = 'numeric', times = 3),

	rep(x = 'NULL', times = 15), # Skip statistical summary variables

	# Acceleration data:
	#   '{total_accel}_dumbbell' variable

	rep(x = 'numeric', times = 1),

	rep(x = 'NULL', times = 10), # Skip statistical summary variables

	# Three-axes gyroscope, acceleration, and magnetometer data:
	#   '{gyro, accel, magnet}_dumbbell_{x, y, z}' variables

	rep(x = 'numeric', times = 9),

	# Forearm
	###########

	# Roll, pitch, yaw data:
	#   '{roll, pitch, yaw}_forearm' variables

	rep(x = 'numeric', times = 3),

	rep(x = 'NULL', times = 15), # Skip statistical summary variables

	# Acceleration data:
	#   '{total_accel}_forearm' variable

	rep(x = 'numeric', times = 1),

	rep(x = 'NULL', times = 10), # Skip statistical summary variables

	# Three-axes gyroscope, acceleration, and magnetometer data:
	#   '{gyro, accel, magnet}_dumbbell_{x, y, z}' variables

	rep(x = 'numeric', times = 9))

# Load 'pml-training.csv'
###########################

training.csv.df <- read.csv(file = 'pml-training.csv',
	header = TRUE,
	na.strings = c('', 'NA', '#DIV/0!'),
	colClasses = c(
		'NULL', # Row name
		'NULL', # 'user_name',
		rep(x = 'NULL', times = 3), # Timestamp
		rep(x = 'NULL', times = 2), # Window

		# Features
		############

		features.colClasses,

		# Classe
		##########

		'character')) %>%
	mutate(classe = factor(x = classe,
		levels = c('A', 'B', 'C', 'D', 'E')))
```

Therefore, our machine learning algorithms will be fed the following dataset: (the code is available in the Appendix)

```{r, echo = FALSE}
str(training.csv.df)
```

```{r features-testing, echo = FALSE}
# Load 'pml-training.csv'
###########################

testing.csv.df <- read.csv(file = 'pml-testing.csv',
	header = TRUE,
	na.strings = c('', 'NA', '#DIV/0!'),
	colClasses = c(
		'NULL', # Row name
		'NULL', # 'user_name',
		rep(x = 'NULL', times = 3), # Timestamp
		rep(x = 'NULL', times = 2), # Window

		# Features
		############

		features.colClasses,

		# Problem Id
		##############

		'numeric'))
```

## Partitioning the `training` dataset into training, validation, and testing

```{r training-validation-testing, echo = FALSE}
# Partition the 'ml-training.csv` dataset into training, validation, and testing

set.seed(0) # Set a seed for reproducibility

partition <- createDataPartition(y = training.csv.df$classe, p = 0.75, list = FALSE)
testing <- training.csv.df[-partition, ] # Testing
training.validation <- training.csv.df[partition, ]

partition <- createDataPartition(y = training.validation$classe, p = 0.75, list = FALSE)
training <- training.validation[partition, ] # Training
validation <- training.validation[-partition, ] # Validation
```

The file `ml-testing.csv` is the set we will be using our model to predict the class of each observation; it isn't the set we will be testing our algorithms.  For that, we are further partitioning our `ml-training.csv` dataset into training (`r format(x = 100 * nrow(training) / nrow(training.csv.df), digits = 0)`%), validation (`r format(x = 100 * nrow(validation) / nrow(training.csv.df), digits = 0)`%), and testing (`r format(x = 100 * nrow(testing) / nrow(training.csv.df), digits = 0)`%):

```{r ref.label = 'training-validation-testing', echo = TRUE, output = FALSE}
```

```{r}
nrow(training)
nrow(validation)
nrow(testing)
```

```{r, echo = FALSE}
assignment.data <- testing.csv.df
```

## Exploratory Data Analysis

We won't go into much details in this section but we plotted the scatter plots for the different `belt` (reproduced below), `arm`, `dumbbell`, and `forearm` predictors (in the Appendix).  For example, we can discern patterns for the `roll`, pitch`, and `yaw` `belt` variables.  We can predict with some confidence that a machine learning algorithm should be able to separate the dependent variable (`classe`) based on these variables.

### Exploratory plots for the `_belt_` predictors

```{r, echo = FALSE, cache = TRUE}
grid.arrange(
	featurePlot(x = select(training, c(roll_belt:yaw_belt)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = '{roll, pitch, yaw}_belt', scales = list(x=list(tick.number = 1))),
	featurePlot(x = select(training, c(gyros_belt_x:gyros_belt_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'gyros_belt_{x, y, z}'),
	featurePlot(x = select(training, c(accel_belt_x:accel_belt_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'accel_belt_{x, y, z}'),
	featurePlot(x = select(training, c(magnet_belt_x:magnet_belt_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'magnet_belt_{x, y, z}'),
	ncol = 2)
```

## Models

```{r algorithms, echo = FALSE}
#########
# train
#########

# part
########

train.rpart <- function(args) {
	train(classe ~ .,
		method = 'rpart',
		data = args$data,
		preProcess = args$preProcess,
		trControl = args$trainControl)
}

# rf
######

train.rf <- function(args) {
	train(classe ~ .,
		method = 'rf',
		data = args$data,
		preProcess = args$preProcess,
		trControl = args$trainControl)
}

# gbm
#######

train.gbm <- function(args) {
	train(classe ~ .,
		method = 'gbm',
		data = args$data,
		preProcess = args$preProcess,
		trControl = args$trainControl)
}

# nb
######

train.nb <- function(args) {
	train(classe ~ .,
		method = 'nb',
		data = args$data,
		preProcess = args$preProcess,
		trControl = args$trainControl)
}

# lda
#######

train.lda <- function(args) {
	train(classe ~ .,
		method = 'lda',
		data = args$data,
		preProcess = args$preProcess,
		trControl = args$trainControl)
}
```

```{r pre-process, echo = FALSE}
###############
# pre_process
###############

pre_process <- list(
	default = NULL,
	center.scale = c('center', 'scale'),
	pca = c('pca')
)
```

```{r train-option, echo = FALSE, message = FALSE}
#################
# train_control
#################

train_control <- list(
	default = trainControl(),
	cv = trainControl(method = 'cv', number = 10),
	rcv = trainControl(method = 'repeatedcv', number = 10, repeats = 5)
)
```

```{r models, echo = FALSE, message = FALSE}
##########
# models
##########

models <- list(
	# Week 3 - "Predicting with trees"

	# rpart
	#########

	'rpart (Default)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$default),
	'rpart (Center and Scale)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$default),
	'rpart (PCA)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$default),

	'rpart (CV)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$cv),
	'rpart (Center and Scale) (CV)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$cv),
	'rpart (PCA) (CV)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$cv),

	'rpart (Repeated CV)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$rcv),
	'rpart (Center and Scale) (Repeated CV)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$rcv),
	'rpart (PCA) (Repeated CV)' = list(method = train.rpart,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$rcv),

	# Week 3 - "Random Forests"

	# rf
	######

	'rf (Default)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$default),
	'rf (Center and Scale)' = list(method = train.rf,
		data = training,
		preProcess =
		pre_process$center.scale,
		trainControl = train_control$default),
	'rf (PCA)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$default),

	'rf (CV)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$cv),
	'rf (Center and Scale) (CV)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$cv),
	'rf (PCA) (CV)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$cv),

	'rf (Repeated CV)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$rcv),
	'rf (Center and Scale) (Repeated CV)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$rcv),
	'rf (PCA) (Repeated CV)' = list(method = train.rf,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$rcv),

	# Week 3 - "Boosting"

	# gbm
	#######

	'gbm (Default)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$default),
	'gbm (Center and Scale)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$default),
	'gbm (PCA)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$default),

	'gbm (CV)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$cv),
	'gbm (Center and Scale) (CV)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$cv),
	'gbm (PCA) (CV)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$cv),

	'gbm (Repeated CV)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$rcv),
	'gbm (Center and Scale) (Repeated CV)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$rcv),
	'gbm (PCA) (Repeated CV)' = list(method = train.gbm,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$rcv),

	# Week 3 - "Model Based Prediction"

	# nb
	######

	'nb (Default)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$default),
	'nb (Center and Scale)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$default),
	'nb (PCA)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$default),

	'nb (CV)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$cv),
	'nb (Center and Scale) (CV)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$cv),
	'nb (PCA) (CV)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$cv),

	'nb (Repeated CV)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$rcv),
	'nb (Center and Scale) (Repeated CV)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$rcv),
	'nb (PCA) (Repeated CV)' = list(method = train.nb,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$rcv),

	# lda
	#######

	'lda (Default)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$default),
	'lda (Center and Scale)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$default),
	'lda (PCA)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$default),

	'lda (CV)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$cv),
	'lda (Center and Scale) (CV)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$cv),
	'lda (PCA) (CV)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$cv),

	'lda (Repeated CV)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$default,
		trainControl = train_control$rcv),
	'lda (Center and Scale) (Repeated CV)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$center.scale,
		trainControl = train_control$rcv),
	'lda (PCA) (Repeated CV)' = list(method = train.lda,
		data = training,
		preProcess = pre_process$pca,
		trainControl = train_control$rcv)
)
```

```{r caching, echo = FALSE}
##############
# cacheModel
##############

cacheModel <- function(file, args) {
	file <- paste0('cache-models/', file, '.rds')
	if (file.exists(file)) {
		return (readRDS(file = file))
	}
	return (1)
	set.seed(0) # Reset the seed so we can freely reo-order algorithms
	model <- args$method(args)
	saveRDS(object = model, file = file, compress = TRUE)
	model
}
```

```{r, echo = FALSE}
names <- names(models)
models <- lapply(X = names,
	FUN = function(name) { cacheModel(name, models[[name]]) })
names(models) <- names
```

We ran multiple machine learning algorithms: trees (`rpart`), random forests (`rf`), boosting (`gbm`), naive bayes (`nb`), and linear discriminant analysis (`lda`) with different pre-processing: `none`, `center-and-scale`, and `pca` (which includes `center-and-scale`) as well as different training methods: `default` (`boot`), `cv` (10-fold cross-validation), and `rcv` (five separate 10-fold cross-validations).

The table below summarizes the different combinations we examined:

| Method | Pre-processing | Resampling |
|---|---|---|
| Recursive Partitioning And Regression Trees (`rpart`) | `none` | Simple bootstrap (`boot`) |
| Random Forests (`rf`) | Center and Scale (`center-and-scale`) | 10-fold cross-validation (`cv`) |
| Gradient Boosting Machines (`gbm`) | Principal Component Analysis (`pca`) | Five separate 10-fold cross-validations (`rcv`) |
| Naive Bayes classifier (`nb`) | | |
| Linear Discriminant Analysis (`lda`) | | |

```{r, echo = FALSE, output = FALSE, message = FALSE, cache = TRUE}
############
# rowTable
############

rowTable <- function(model) {
	training.accuracy <- confusionMatrix(training$classe,
		predict(model, newdata = training))$overall['Accuracy']

	validation.accuracy <- confusionMatrix(validation$classe,
		predict(model, newdata = validation))$overall['Accuracy']

	validation.out.of.sample.error <- 1 - validation.accuracy

	testing.accuracy <- confusionMatrix(testing$classe,
		predict(model, newdata = testing))$overall['Accuracy']

	testing.out.of.sample.error <- 1 - testing.accuracy

	prediction <- predict(model, newdata = assignment.data)

	list(training.accuracy = format(x = 100 * training.accuracy,
			digits = 1, scientific = FALSE),
		validation.accuracy = format(x = 100 * validation.accuracy,
			digits = 1, scientific = FALSE),
		validation.out.of.sample.error =
			format(x = 100 * validation.out.of.sample.error,
				digits = 1, scientific = FALSE),
		testing.accuracy = format(x = 100 * testing.accuracy,
			digits = 1, scientific = FALSE),
		testing.out.of.sample.error =
			format(x = 100 * testing.out.of.sample.error,
				digits = 1, scientific = FALSE),
		prediction = as.character(prediction))
}

#################
# cacheRowTable
#################

cacheRowTable <- function(name, model) {
	file <- paste0('cache-table/', name, '.rds')
	if (file.exists(file)) {
		return (readRDS(file = file))
	}

	row_table <- rowTable(model)
	saveRDS(object = row_table, file = file, compress = TRUE)
	row_table
}

table <- lapply(X = names(models), FUN = function(name) { cacheRowTable(name, models[[name]]) })

table <- matrix(unlist(table), nrow = length(table), byrow = TRUE)

colnames(table) <- c("Training\naccuracy (%)",
	"Validation\naccuracy (%)",
	"Out-of-sample\nvalidation\nerror (%)",
	"Testing\nAccuracy (%)",
	"Out-of-sample\ntesting\nerror (%)",
	sapply(X = 1 : nrow(assignment.data),
		FUN = function(i) { paste0("id\n#", i) }))

rownames(table) <- names(models)

models.table <- function(table, b = nrow(assignment.data)) {
	a <- dim(table)[2] - b
	print(xtable(table,
		align = paste0(c('l',
			rep(x = 'r', times = a),
			rep(x = 'c', times = b)), collapse = '')),
		include.rownames = TRUE,
		type = 'html')
}
```

The results are shown below.  `rf` performed the best ($accuracy = `r table['rf (Default)', 2]`\%; out-of-sample-error = 1 - accuracy = `r table['rf (Default)', 3]`\%$.  `PCA` lowered `rf`'s accuracy quite dramatically but any other combination without `PCA` seems to be perform similarly.  The second best-performing algorithm was `gbm` ($accuracy \approx `r table['gbm (Default)', 2]`\%$); `nb` and `lda` were distant third ($accuracy \approx `r table['nb (Default)', 2]`\%$ and $accuracy \approx `r table['lda (Default)', 2]`\%$) and `rpart` closed the mark with a poor performance ($accuracy \approx `r table['rpart (Default)', 2]`\%$).

```{r, echo = FALSE, results = 'asis'}
models.table(table[, 1:3], 0)
```

Because `rf (Default)` gives such good results, we are selecting it as our predictive model.  It would seem therefore that our use of separate `validation` and `testing` set wasn't warranted.  However, if we had to go back and tune our models, we would still have a pristine `testing` set to validate our out-of-sample error once we were ready to pick a model.

```{r, echo = FALSE, output = FALSE}
final.model <- 'rf (Default)'
```

```{r, echo = FALSE, results = 'asis'}
models.table(table[final.model, 1:5, drop = FALSE], 0)
```

Our out-of-sample eror for the `testing` set ($`r table[final.model, 5]`\%$) is in line with the `validation` out-of-sample eror ($`r table[final.model, 3]`\%$), if not slightly better.

Finally, applying our final model to the observations in the `ml-testing.csv` file, we predict that these observations below to the following classes:

```{r, echo = FALSE, results = 'asis'}
models.table(table[final.model, 6 : ncol(table), drop = FALSE])
```

```{r, echo = FALSE, message = FALSE}
pml_write_files <- function(prediction) {
	for (i in 1 : length(prediction)) {
		write.table(x = prediction[i],
			file = paste0('problem_id_', i, '.txt'),
			quote = FALSE,
			row.names = FALSE,
			col.names = FALSE)
	}
}

prediction <- as.character(predict(models[final.model], newdata = assignment.data))

pml_write_files(prediction)
```

This concludes our report.  Please feel free to peruse the Appendix for more details (mostly geared towards our implementation).

# Appendix

## Code - Load the `training` dataset with our shortlist of `r ncol(training.csv.df) - 1` features

```{r ref.label = 'features-training', echo = TRUE, output = FALSE}
```
## Code - Load the `testing` dataset with our feature list

```{r ref.label = 'features-testing', echo = TRUE, output = FALSE}
```

## `testing` dataset variables
```{r}
str(testing.csv.df)
```

## No missing data and no zero variance predictors in the datasets

```{r}
sum(colSums(is.na(training.csv.df)))
nearZeroVar(x = select(training.csv.df, -c(classe)))
sum(colSums(is.na(testing.csv.df)))
nearZeroVar(x = select(testing.csv.df, -c(problem_id)))
```

## Exploratory Analysis

### Exploratory plots for the `_arm_` predictors

```{r, echo = FALSE, cache = TRUE}
grid.arrange(
	featurePlot(x = select(training, c(roll_arm:yaw_arm)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = '{roll, pitch, yaw}_arm', scales = list(x=list(tick.number = 1))),
	featurePlot(x = select(training, c(gyros_arm_x:gyros_arm_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'gyros_arm_{x, y, z}'),
	featurePlot(x = select(training, c(accel_arm_x:accel_arm_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'accel_arm_{x, y, z}'),
	featurePlot(x = select(training, c(magnet_arm_x:magnet_arm_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'magnet_arm_{x, y, z}'),
	ncol = 2)
```

### Exploratory plots for the `_dumbbell_` predictors

```{r, echo = FALSE, cache = TRUE}
grid.arrange(
	featurePlot(x = select(training, c(roll_dumbbell:yaw_dumbbell)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = '{roll, pitch, yaw}_dumbbell', scales = list(x=list(tick.number = 1))),
	featurePlot(x = select(training, c(gyros_dumbbell_x:gyros_dumbbell_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'gyros_dumbbell_{x, y, z}'),
	featurePlot(x = select(training, c(accel_dumbbell_x:accel_dumbbell_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'accel_dumbbell_{x, y, z}'),
	featurePlot(x = select(training, c(magnet_dumbbell_x:magnet_dumbbell_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'magnet_dumbbell_{x, y, z}'),
	ncol = 2)
```

### Exploratory plots for the `_forearm_` predictors

```{r, echo = FALSE, cache = TRUE}
grid.arrange(
	featurePlot(x = select(training, c(roll_forearm:yaw_forearm)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = '{roll, pitch, yaw}_forearm', scales = list(x=list(tick.number = 1))),
	featurePlot(x = select(training, c(gyros_forearm_x:gyros_forearm_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'gyros_forearm_{x, y, z}'),
	featurePlot(x = select(training, c(accel_forearm_x:accel_forearm_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'accel_forearm_{x, y, z}'),
	featurePlot(x = select(training, c(magnet_forearm_x:magnet_forearm_y)),
		y = training$classe,
		plot = 'pairs',
		auto.key = list(columns = 3),
		main = 'magnet_forearm_{x, y, z}'),
	ncol = 2)
```

## Models

### `preProcess`'ing options: `default`, `center and scale`, and `PCA`
```{r ref.label = 'pre-process', echo = TRUE, output = FALSE}
```

### `trainControl` options: `default` (`method = 'boot'`), `cv` (`center and scale`), and `PCA`

```{r ref.label = 'train-option', echo = TRUE, output = FALSE}
```

### `rpart` ,`rf`, `gbm`, `nb`, and `lba` machine learning algorithms

```{r ref.label = 'algorithms', echo = TRUE, output = FALSE}
```

### Implementation: Models are cached on disk and retreived on demand

```{r ref.label = 'caching', echo = TRUE, output = FALSE}
```

### The full model combination

```{r ref.label = 'models', echo = TRUE, output = FALSE, message = FALSE}
```

### The models' accuracy, out-of-sample error, and predictions table

```{r, echo = FALSE, results = 'asis'}
models.table(table)
```

